dataset:
  name: textvqa
  root: ./data_pipeline/data/textvqa
  batch_size: 4
  num_workers: 2
corruption:
  blur_prob: 0.3
  occlusion_prob: 0.3
  crop_prob: 0.2
  ocr_noise_prob: 0.4
retrieval:
  top_k: 5
  noise_threshold: 0.6
model:
  hidden_size: 256
  question_length: 32
  vision_tokens: 16
  prefix_length: 32
  memory_tokens: 16
  imputation_tokens: 8
  vocab_size: 8192
training:
  epochs: 3
  lr_backbone: 1.0e-5
  lr_adapter: 5.0e-5
  log_interval: 20
evaluation:
  benchmarks:
    - textvqa
    - chartqa
    - docvqa
