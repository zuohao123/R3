dataset:
  root: ./data_pipeline/data/textvqa
  split: train
  eval_split: val
  batch_size: 2
  num_workers: 0
  pseudo_corpus: null   # optional path to build_pseudo_text.py output JSONL for offline pseudo-text
model:
  name: Qwen/Qwen3-VL-8B-Instruct
  lora_rank: 32
  lora_alpha: 16
  hidden_size: 4096
  provider: modelscope  # 可切换为 modelscope huggingface
  token: null            # 私有模型可填 HF token 或魔搭 token
  cache_dir: ./hf_cache
  revision: null
  local_files_only: false
  enable_corruption: true
  enable_retrieval: true
  enable_prefix: true
  enable_memory: true
  enable_imputation: true
  enable_consistency: true
  lambda_consistency: 0.3
  top_k: 3
training:
  epochs: 1
  log_interval: 10
  learning_rate: 0.0002
  weight_decay: 0.05
  warmup_ratio: 0.05
evaluation:
  split: val
  apply_corruption: false
  batch_size: 2
